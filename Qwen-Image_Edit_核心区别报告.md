# Qwen-Image-Edit æ ¸å¿ƒåŒºåˆ«æŠ¥å‘Šï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

Qwen-Image-Edit çš„æ ¸å¿ƒåˆ›æ–°æ˜¯**åŒè·¯å¾„æ¶æ„**ï¼šå›¾åƒåŒæ—¶é€å…¥ Qwen2.5-VLï¼ˆè¯­ä¹‰æ§åˆ¶ï¼‰å’Œ VAEï¼ˆå¤–è§‚æ§åˆ¶ï¼‰ï¼Œå®ç°ç²¾ç¡®çš„å›¾åƒç¼–è¾‘ã€‚

---

## â­ ä¸€ã€æœ€é‡è¦ï¼šåŒè·¯å¾„è¾“å…¥æ¶æ„

### 1.1 æ•´ä½“æ¶æ„å¯¹æ¯”

#### åŸç‰ˆ Qwen-Image
```
è¾“å…¥: æ–‡æœ¬ Prompt
  â†“
Tokenizer
  â†“
Text Encoder (ä»…å¤„ç†æ–‡æœ¬)
  â†“
Prompt Embeddings
  â†“
å»å™ªå¾ªç¯ç”Ÿæˆå›¾åƒ
```

#### Edit ç‰ˆæœ¬ï¼ˆåŒè·¯å¾„ï¼‰
```
è¾“å…¥å›¾åƒ â”€â”€â”¬â”€â”€â†’ Qwen2.5-VL â”€â”€â†’ å¤šæ¨¡æ€ Embeddings â”€â”
           â”‚                                    â”‚
           â””â”€â”€â†’ VAE Encoder â”€â”€â†’ Image Latents â”€â”€â”¼â”€â”€â†’ å»å™ªå¾ªç¯
                                                â”‚
æ–‡æœ¬ Prompt â”€â”€â”€â†’ Processor â”€â”€â”€â†’ Text Encoder â”€â”€â”˜
```

### 1.2 ä»£ç å®ç°ï¼šåŒè·¯å¾„çš„æ ¸å¿ƒ

#### è·¯å¾„1ï¼šQwen2.5-VLï¼ˆè¯­ä¹‰ç†è§£ï¼‰

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:226-271
def _get_qwen_prompt_embeds(
    self,
    prompt: Union[str, List[str]] = None,
    image: Optional[torch.Tensor] = None,  # â­ å…³é”®ï¼šæ¥æ”¶å›¾åƒ
    device: Optional[torch.device] = None,
    dtype: Optional[torch.dtype] = None,
):
    txt = [template.format(e) for e in prompt]
    
    # â­ æ ¸å¿ƒï¼šprocessor åŒæ—¶å¤„ç†æ–‡æœ¬å’Œå›¾åƒ
    model_inputs = self.processor(
        text=txt,
        images=image,  # å›¾åƒè¾“å…¥
        padding=True,
        return_tensors="pt",
    ).to(device)
    
    # â­ æ ¸å¿ƒï¼štext_encoder æ¥æ”¶å¤šæ¨¡æ€è¾“å…¥
    outputs = self.text_encoder(
        input_ids=model_inputs.input_ids,
        attention_mask=model_inputs.attention_mask,
        pixel_values=model_inputs.pixel_values,      # å›¾åƒåƒç´ 
        image_grid_thw=model_inputs.image_grid_thw,  # å›¾åƒå¸ƒå±€
        output_hidden_states=True,
    )
    
    return prompt_embeds, encoder_attention_mask
```

**å…³é”®ç‚¹**ï¼š
- âœ… `processor` å°†å›¾åƒå’Œæ–‡æœ¬æ‰“åŒ…ä¸ºå¤šæ¨¡æ€è¾“å…¥
- âœ… `text_encoder` åŒæ—¶å¤„ç†æ–‡æœ¬ tokens å’Œå›¾åƒåƒç´ 
- âœ… è¾“å‡ºçš„ embeddings åŒ…å«**å›¾åƒè¯­ä¹‰ç†è§£**

#### è·¯å¾„2ï¼šVAE Encoderï¼ˆè§†è§‰å¤–è§‚ï¼‰

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:395-416
def _encode_vae_image(self, image: torch.Tensor, generator: torch.Generator):
    # â­ å…³é”®ï¼šVAE ç¼–ç å›¾åƒä¸º latent
    image_latents = retrieve_latents(
        self.vae.encode(image), 
        generator=generator, 
        sample_mode="argmax"  # ç¡®å®šæ€§ç¼–ç 
    )
    
    # å½’ä¸€åŒ–å¤„ç†
    latents_mean = torch.tensor(self.vae.config.latents_mean)
    latents_std = torch.tensor(self.vae.config.latents_std)
    image_latents = (image_latents - latents_mean) / latents_std
    
    return image_latents
```

**å…³é”®ç‚¹**ï¼š
- âœ… VAE å°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤º
- âœ… `argmax` æ¨¡å¼ç¡®ä¿ç¼–ç ç¨³å®šæ€§
- âœ… æä¾›**è§†è§‰å¤–è§‚å‚è€ƒ**

### 1.3 åŒè·¯å¾„æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç¼–è¾‘ä»»åŠ¡å¼€å§‹                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥å›¾åƒ       â”‚            â”‚  æ–‡æœ¬ç¼–è¾‘æŒ‡ä»¤     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
        â”‚             â”‚                  â”‚
        â–¼             â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VAE Encoder â”‚  â”‚Processor â”‚    â”‚  Text Token  â”‚
â”‚             â”‚  â”‚          â”‚    â”‚              â”‚
â”‚ ç¼–ç è§†è§‰ç‰¹å¾â”‚  â”‚ å¤šæ¨¡æ€å¤„ç†â”‚    â”‚  æ–‡æœ¬token   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚                  â”‚
       â”‚              â–¼                  â”‚
       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
       â”‚       â”‚  Text Encoder â”‚         â”‚
       â”‚       â”‚ (Qwen2.5-VL)  â”‚         â”‚
       â”‚       â”‚               â”‚         â”‚
       â”‚       â”‚ å¤„ç†æ–‡æœ¬+å›¾åƒ â”‚         â”‚
       â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
       â”‚               â”‚                â”‚
       â”‚               â–¼                â”‚
       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
       â”‚       â”‚ å¤šæ¨¡æ€Embeddingsâ”‚       â”‚
       â”‚       â”‚ (è¯­ä¹‰ç†è§£)    â”‚        â”‚
       â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
       â”‚               â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  å‡†å¤‡Latents     â”‚
      â”‚                  â”‚
      â”‚ Image Latents   â”‚ â† æ¥è‡ªVAE
      â”‚ (è§†è§‰å‚è€ƒ)       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   å»å™ªå¾ªç¯       â”‚
      â”‚                  â”‚
      â”‚ [å»å™ªlatents +   â”‚
      â”‚  å›¾åƒlatents]    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Transformer      â”‚
      â”‚                  â”‚
      â”‚ æ¥æ”¶:            â”‚
      â”‚ â€¢ æ‹¼æ¥çš„latents  â”‚
      â”‚ â€¢ å¤šæ¨¡æ€embeddingsâ”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        ç¼–è¾‘åçš„å›¾åƒ
```

---

## ğŸ”¥ äºŒã€å»å™ªå¾ªç¯ä¸­çš„ Latent æ‹¼æ¥ç­–ç•¥

### 2.1 æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

#### åŸç‰ˆï¼šä»…ä½¿ç”¨å»å™ª latents
```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage.py
for i, t in enumerate(timesteps):
    latent_model_input = latents  # åªæœ‰å»å™ªçš„latents
    
    noise_pred = self.transformer(
        hidden_states=latent_model_input,
        encoder_hidden_states=prompt_embeds,
        ...
    )
```

#### Edit ç‰ˆæœ¬ï¼šæ‹¼æ¥åŸå§‹å›¾åƒ latents
```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:810-828
for i, t in enumerate(timesteps):
    latent_model_input = latents  # å½“å‰å»å™ªçŠ¶æ€
    
    # â­ å…³é”®ï¼šæ‹¼æ¥åŸå§‹å›¾åƒ latents
    if image_latents is not None:
        latent_model_input = torch.cat([latents, image_latents], dim=1)
        #           â†‘ å½“å‰å»å™ª       â†‘ åŸå§‹å›¾åƒç‰¹å¾
        #         [B, seq_len1, C] + [B, seq_len2, C]
        #         = [B, seq_len1+seq_len2, C]
    
    # Transformer åŒæ—¶çœ‹åˆ°å»å™ªçŠ¶æ€å’ŒåŸå§‹å›¾åƒ
    noise_pred = self.transformer(
        hidden_states=latent_model_input,  # æ‹¼æ¥åçš„è¾“å…¥
        encoder_hidden_states=prompt_embeds,  # åŒ…å«å›¾åƒç†è§£
        ...
    )
    
    # â­ åªå–å‰éƒ¨åˆ†ï¼ˆå¯¹åº”å»å™ªéƒ¨åˆ†ï¼‰
    noise_pred = noise_pred[:, : latents.size(1)]
```

### 2.2 æ‹¼æ¥ç­–ç•¥æµç¨‹å›¾

```
å»å™ªæ­¥éª¤ t
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å½“å‰ Latents    â”‚ â† æ­£åœ¨å»å™ªçš„éƒ¨åˆ†
â”‚ [B, L1, C]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ torch.cat([:, dim=1])
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åŸå§‹å›¾åƒ Latentsâ”‚ â”‚ å½“å‰å»å™ª Latentsâ”‚
â”‚ [B, L2, C]      â”‚ â”‚ [B, L1, C]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Latent Model Input    â”‚
    â”‚ [B, L1+L2, C]         â”‚
    â”‚                        â”‚
    â”‚ [å»å™ªéƒ¨åˆ† | åŸå›¾éƒ¨åˆ†]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Transformer         â”‚
    â”‚                        â”‚
    â”‚ è¾“å…¥:                  â”‚
    â”‚ â€¢ æ‹¼æ¥çš„ latents       â”‚
    â”‚ â€¢ å¤šæ¨¡æ€ embeddings    â”‚
    â”‚                        â”‚
    â”‚ è¾“å‡º:                  â”‚
    â”‚ â€¢ å™ªå£°é¢„æµ‹ [B, L1+L2]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ æˆªå–å‰ L1 éƒ¨åˆ†        â”‚
    â”‚ noise_pred[:, :L1]    â”‚
    â”‚ (åªç”¨äºå»å™ªæ›´æ–°)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜åŠ¿**ï¼š
- âœ… Transformer åŒæ—¶è®¿é—®å»å™ªçŠ¶æ€å’ŒåŸå§‹å›¾åƒ
- âœ… å®ç°ç²¾ç¡®çš„åŒºåŸŸæ§åˆ¶ï¼ˆå“ªäº›æ”¹ã€å“ªäº›ä¸å˜ï¼‰
- âœ… ä¿æŒè§†è§‰ä¸€è‡´æ€§

### 2.3 åŸå§‹å›¾åƒ Latents çš„å†»ç»“æœºåˆ¶

**é—®é¢˜**ï¼šæ—¢ç„¶åŸå§‹å›¾åƒ latents ä¸æ›´æ–°ï¼Œè®¡ç®—è¿‡ç¨‹ä¸­æ˜¯å¦åšäº†å†»ç»“å¤„ç†ï¼Ÿ

**ç­”æ¡ˆåˆ†æ**ï¼š

#### 1. å…¨å±€ `@torch.no_grad()` è£…é¥°å™¨

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:546
@torch.no_grad()  # â­ æ•´ä¸ªæ¨ç†è¿‡ç¨‹åœ¨æ— æ¢¯åº¦æ¨¡å¼ä¸‹
@replace_example_docstring(EXAMPLE_DOC_STRING)
def __call__(self, ...):
    # æ‰€æœ‰è®¡ç®—éƒ½åœ¨ no_grad æ¨¡å¼ä¸‹
    ...
```

**å½±å“**ï¼šæ•´ä¸ª `__call__` æ–¹æ³•åœ¨æ— æ¢¯åº¦æ¨¡å¼ä¸‹è¿è¡Œï¼Œç†è®ºä¸Š**æ‰€æœ‰å¼ é‡éƒ½ä¸è®¡ç®—æ¢¯åº¦**ã€‚

#### 2. åŸå§‹å›¾åƒ Latents çš„ç”Ÿæˆ

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:395-416
def _encode_vae_image(self, image: torch.Tensor, generator: torch.Generator):
    # VAE ç¼–ç ï¼ˆåœ¨ no_grad ä¸Šä¸‹æ–‡ä¸­ï¼‰
    image_latents = retrieve_latents(
        self.vae.encode(image), 
        generator=generator, 
        sample_mode="argmax"  # ç¡®å®šæ€§ç¼–ç 
    )
    # å½’ä¸€åŒ–åè¿”å›
    return image_latents  # â­ è¿™äº› latents åœ¨ no_grad æ¨¡å¼ä¸‹ç”Ÿæˆ
```

#### 3. å»å™ªå¾ªç¯ä¸­çš„ä½¿ç”¨

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:810-828
for i, t in enumerate(timesteps):
    latent_model_input = latents
    
    # â­ ç›´æ¥æ‹¼æ¥ï¼Œæ²¡æœ‰æ˜¾å¼çš„ .detach()
    if image_latents is not None:
        latent_model_input = torch.cat([latents, image_latents], dim=1)
    
    # Transformer è°ƒç”¨ï¼ˆåœ¨ no_grad æ¨¡å¼ä¸‹ï¼‰
    noise_pred = self.transformer(
        hidden_states=latent_model_input,
        ...
    )
    
    # â­ åªå–å‰éƒ¨åˆ†ï¼ˆå»å™ªéƒ¨åˆ†ï¼‰ç”¨äºæ›´æ–°
    noise_pred = noise_pred[:, : latents.size(1)]
    
    # æ›´æ–° latentsï¼ˆåªæ›´æ–°å»å™ªéƒ¨åˆ†ï¼‰
    latents = self.scheduler.step(noise_pred, t, latents, ...)[0]
    # â­ image_latents ä¸ä¼šåœ¨è¿™é‡Œæ›´æ–°
```

### 2.4 å†»ç»“æœºåˆ¶æ€»ç»“

| æœºåˆ¶ | å®ç°æ–¹å¼ | è¯´æ˜ |
|------|---------|------|
| **å…¨å±€æ— æ¢¯åº¦** | `@torch.no_grad()` | æ•´ä¸ªæ¨ç†è¿‡ç¨‹ä¸è®¡ç®—æ¢¯åº¦ |
| **éšå¼å†»ç»“** | `image_latents` ç”Ÿæˆåå›ºå®š | åªå‚ä¸å‰å‘ä¼ æ’­ï¼Œä¸å‚ä¸æ›´æ–° |
| **æ˜¾å¼å†»ç»“** | âŒ **æœªå®ç°** | ä»£ç ä¸­æ²¡æœ‰ `.detach()` æˆ– `.requires_grad_(False)` |

**ä¸ºä»€ä¹ˆä¸éœ€è¦æ˜¾å¼å†»ç»“ï¼Ÿ**

1. âœ… **æ¨ç†æ¨¡å¼**ï¼š`@torch.no_grad()` ä½¿æ•´ä¸ªæµç¨‹ä¸è®¡ç®—æ¢¯åº¦
2. âœ… **æ›´æ–°æœºåˆ¶**ï¼šåªæœ‰ `latents` é€šè¿‡ `scheduler.step()` æ›´æ–°ï¼Œ`image_latents` ä¸å‚ä¸æ›´æ–°
3. âœ… **è®¡ç®—æ•ˆç‡**ï¼šåœ¨ `no_grad` æ¨¡å¼ä¸‹ï¼ŒPyTorch è‡ªåŠ¨ä¼˜åŒ–ï¼Œä¸ä¼šä¸ºä¸å˜å¼ é‡åˆ†é…æ¢¯åº¦ç¼“å­˜

**æ½œåœ¨ä¼˜åŒ–ï¼ˆå¦‚æœéœ€è¦åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼‰**ï¼š

```python
# å¦‚æœå°†æ¥éœ€è¦æ”¯æŒè®­ç»ƒæ¨¡å¼ï¼Œå¯ä»¥è€ƒè™‘æ˜¾å¼å†»ç»“
if image_latents is not None:
    # é€‰é¡¹1: detach
    image_latents = image_latents.detach()
    
    # é€‰é¡¹2: requires_grad=False
    image_latents.requires_grad_(False)
    
    latent_model_input = torch.cat([latents, image_latents], dim=1)
```

**æµç¨‹å›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ @torch.no_grad()               â”‚ â† å…¨å±€æ— æ¢¯åº¦æ¨¡å¼
â”‚ (æ•´ä¸ªæ¨ç†è¿‡ç¨‹)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prepare_latents()               â”‚
â”‚                                 â”‚
â”‚ â€¢ image_latents â† VAEç¼–ç        â”‚ â† ç”Ÿæˆåå›ºå®š
â”‚ â€¢ latents â† éšæœºå™ªå£°            â”‚ â† ä¼šæ›´æ–°
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å»å™ªå¾ªç¯ (50æ­¥)                 â”‚
â”‚                                 â”‚
â”‚ for each timestep:              â”‚
â”‚   latent_model_input =           â”‚
â”‚      cat([latents, image_latents])â”‚
â”‚                                 â”‚
â”‚   noise_pred = transformer(...) â”‚ â† å‰å‘ä¼ æ’­
â”‚                                 â”‚
â”‚   noise_pred = noise_pred[:, :L1]â”‚ â† åªå–å»å™ªéƒ¨åˆ†
â”‚                                 â”‚
â”‚   latents = scheduler.step(...)  â”‚ â† åªæ›´æ–° latents
â”‚   # image_latents ä¿æŒä¸å˜      â”‚ â† âœ… éšå¼å†»ç»“
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç»“è®º**ï¼š
- âœ… å½“å‰å®ç°é€šè¿‡ `@torch.no_grad()` å®ç°éšå¼å†»ç»“
- âœ… `image_latents` åªå‚ä¸å‰å‘ä¼ æ’­ï¼Œä¸å‚ä¸æ›´æ–°
- âœ… åœ¨æ¨ç†æ¨¡å¼ä¸‹ï¼Œè¿™ç§è®¾è®¡æ˜¯é«˜æ•ˆä¸”å®‰å…¨çš„
- âš ï¸ å¦‚æœéœ€è¦è®­ç»ƒæ¨¡å¼ï¼Œå»ºè®®æ˜¾å¼æ·»åŠ  `.detach()` æˆ– `.requires_grad_(False)`

---

## ğŸ“ ä¸‰ã€å¤šæ¨¡æ€ Prompt ç¼–ç å·®å¼‚

### 3.1 ç¼–ç æµç¨‹å¯¹æ¯”

#### åŸç‰ˆï¼šçº¯æ–‡æœ¬ç¼–ç 
```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage.py:188-224
def _get_qwen_prompt_embeds(self, prompt, device, dtype):
    # 1. æ–‡æœ¬æ¨¡æ¿
    txt = [template.format(e) for e in prompt]
    
    # 2. ä»…æ–‡æœ¬ tokenization
    txt_tokens = self.tokenizer(txt, ...)
    
    # 3. ä»…æ–‡æœ¬ç¼–ç 
    encoder_hidden_states = self.text_encoder(
        input_ids=txt_tokens.input_ids,
        attention_mask=txt_tokens.attention_mask,
        # âŒ æ— å›¾åƒè¾“å…¥
    )
```

#### Edit ç‰ˆæœ¬ï¼šå¤šæ¨¡æ€ç¼–ç 
```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:226-271
def _get_qwen_prompt_embeds(self, prompt, image, device, dtype):
    txt = [template.format(e) for e in prompt]
    
    # â­ å…³é”®ï¼šprocessor å¤„ç†å¤šæ¨¡æ€
    model_inputs = self.processor(
        text=txt,
        images=image,  # âœ… å›¾åƒè¾“å…¥
        ...
    )
    
    # â­ å…³é”®ï¼štext_encoder æ¥æ”¶å›¾åƒ
    outputs = self.text_encoder(
        input_ids=model_inputs.input_ids,
        attention_mask=model_inputs.attention_mask,
        pixel_values=model_inputs.pixel_values,      # âœ… å›¾åƒ
        image_grid_thw=model_inputs.image_grid_thw,  # âœ… å¸ƒå±€
    )
```

### 3.2 Prompt æ¨¡æ¿å·®å¼‚

#### åŸç‰ˆæ¨¡æ¿ï¼ˆæè¿°å›¾åƒï¼‰
```python
prompt_template_encode = (
    "<|im_start|>system\n"
    "Describe the image by detailing the color, shape, size, "
    "texture, quantity, text, spatial relationships of the objects "
    "and background:<|im_end|>\n"
    "<|im_start|>user\n{}<|im_end|>\n"
    "<|im_start|>assistant\n"
)
# åŠŸèƒ½ï¼šæè¿°å›¾åƒå†…å®¹
```

#### Edit ç‰ˆæœ¬æ¨¡æ¿ï¼ˆç†è§£ç¼–è¾‘æŒ‡ä»¤ï¼‰
```python
prompt_template_encode = (
    "<|im_start|>system\n"
    "Describe the key features of the input image (color, shape, "
    "size, texture, objects, background), then explain how the "
    "user's text instruction should alter or modify the image. "
    "Generate a new image that meets the user's requirements while "
    "maintaining consistency with the original input where appropriate."
    "<|im_end|>\n"
    "<|im_start|>user\n"
    "<|vision_start|><|image_pad|><|vision_end|>{}<|im_end|>\n"
    "<|im_start|>assistant\n"
)
# åŠŸèƒ½ï¼šç†è§£ç¼–è¾‘æŒ‡ä»¤å¹¶ç”Ÿæˆæ–°å›¾åƒ
# â­ åŒ…å«å›¾åƒå ä½ç¬¦: <|vision_start|><|image_pad|><|vision_end|>
```

**å…³é”®å·®å¼‚**ï¼š
- âœ… Edit æ¨¡æ¿åŒ…å«å›¾åƒå ä½ç¬¦
- âœ… å¼•å¯¼æ¨¡å‹ç†è§£"å¦‚ä½•ä¿®æ”¹"è€Œé"æè¿°ä»€ä¹ˆ"
- âœ… å¼ºè°ƒ"ä¿æŒä¸€è‡´æ€§"

### 3.3 ç¼–ç æµç¨‹å¯¹æ¯”å›¾

```
åŸç‰ˆ Qwen-Image:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–‡æœ¬    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Tokenizerâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Text Encoder â”‚
â”‚ (ä»…æ–‡æœ¬)    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Text Embeddingsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Edit ç‰ˆæœ¬:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–‡æœ¬    â”‚  â”‚ å›¾åƒ    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Processor   â”‚
    â”‚ (å¤šæ¨¡æ€æ‰“åŒ…) â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Text Encoder  â”‚
    â”‚(Qwen2.5-VL)  â”‚
    â”‚              â”‚
    â”‚ åŒæ—¶å¤„ç†:     â”‚
    â”‚ â€¢ æ–‡æœ¬tokens â”‚
    â”‚ â€¢ å›¾åƒåƒç´    â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚å¤šæ¨¡æ€Embeddingsâ”‚
    â”‚ (æ–‡æœ¬+å›¾åƒè¯­ä¹‰) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ å››ã€å›¾åƒé¢„å¤„ç†ä¸ VAE ç¼–ç 

### 4.1 Edit ç‰ˆæœ¬ç‹¬æœ‰çš„å›¾åƒç¼–ç æ–¹æ³•

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:395-416
def _encode_vae_image(self, image: torch.Tensor, generator: torch.Generator):
    # â­ VAE ç¼–ç å›¾åƒ
    image_latents = retrieve_latents(
        self.vae.encode(image), 
        generator=generator, 
        sample_mode="argmax"  # ç¡®å®šæ€§ç¼–ç 
    )
    
    # å½’ä¸€åŒ–åˆ° VAE æ½œåœ¨ç©ºé—´
    latents_mean = torch.tensor(self.vae.config.latents_mean)
    latents_std = torch.tensor(self.vae.config.latents_std)
    image_latents = (image_latents - latents_mean) / latents_std
    
    return image_latents
```

**è°ƒç”¨ä½ç½®**ï¼š
```python
# prepare_latents ä¸­
if image is not None:
    image_latents = self._encode_vae_image(image=image, generator=generator)
    image_latents = self._pack_latents(image_latents, ...)
```

### 4.2 VAE ç¼–ç æµç¨‹å›¾

```
è¾“å…¥å›¾åƒ [B, C, H, W]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚VAE Encoder â”‚
â”‚  (å‹ç¼©ç¼–ç ) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Image Latentsâ”‚
â”‚ [B, Z, H', W']â”‚
â”‚ (å‹ç¼©ç‰¹å¾)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å½’ä¸€åŒ–     â”‚
â”‚ (å‡å»å‡å€¼)  â”‚
â”‚ (é™¤ä»¥æ ‡å‡†å·®)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pack Latentsâ”‚
â”‚ (æ‰“åŒ…ä¸ºåºåˆ—)â”‚
â”‚ [B, L, C]   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   å­˜å‚¨ä¸º image_latents
   ç”¨äºå»å™ªå¾ªç¯æ‹¼æ¥
```

---

## ğŸ”§ äº”ã€åˆå§‹åŒ–å·®å¼‚

### 5.1 æ–°å¢ Processor ç»„ä»¶

#### åŸç‰ˆåˆå§‹åŒ–
```python
# pipelines/qwenimage/pipeline_qwenimage.py:154-170
def __init__(
    self,
    scheduler,
    vae,
    text_encoder,
    tokenizer,          # âš ï¸ æ—  processor
    transformer,
):
    self.register_modules(
        vae=vae,
        text_encoder=text_encoder,
        tokenizer=tokenizer,
        transformer=transformer,
        scheduler=scheduler,
    )
```

#### Edit ç‰ˆæœ¬åˆå§‹åŒ–
```python
# pipelines/qwenimage/pipeline_qwenimage_edit.py:187-205
def __init__(
    self,
    scheduler,
    vae,
    text_encoder,
    tokenizer,
    processor,          # â­ æ–°å¢
    transformer,
):
    self.register_modules(
        vae=vae,
        text_encoder=text_encoder,
        tokenizer=tokenizer,
        processor=processor,  # â­ æ³¨å†Œ processor
        transformer=transformer,
        scheduler=scheduler,
    )
```

**Processor ä½œç”¨**ï¼š
- âœ… å°†æ–‡æœ¬å’Œå›¾åƒæ‰“åŒ…ä¸ºå¤šæ¨¡æ€è¾“å…¥
- âœ… ç”Ÿæˆ `pixel_values` å’Œ `image_grid_thw`
- âœ… æ˜¯åŒè·¯å¾„æ¶æ„çš„å…³é”®ç»„ä»¶

---

## ğŸ“Š å…­ã€æ•°æ®æµå¯¹æ¯”æ€»ç»“

### 6.1 åŸç‰ˆ Qwen-Image å®Œæ•´æµç¨‹

```
æ–‡æœ¬ Prompt
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Tokenizer â”‚ â†’ æ–‡æœ¬ tokens
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Text Encoderâ”‚ â†’ æ–‡æœ¬ embeddings
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ç”Ÿæˆéšæœº  â”‚ â†’ åˆå§‹ latents [B, L, C]
â”‚    å™ªå£°      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. å»å™ªå¾ªç¯  â”‚
â”‚    50æ­¥      â”‚
â”‚              â”‚
â”‚ Transformer: â”‚
â”‚ â€¢ latents    â”‚
â”‚ â€¢ embeddings â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. VAE Decodeâ”‚ â†’ ç”Ÿæˆå›¾åƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Edit ç‰ˆæœ¬å®Œæ•´æµç¨‹

```
è¾“å…¥å›¾åƒ + æ–‡æœ¬æŒ‡ä»¤
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
    â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Processor â”‚         â”‚VAE Encodeâ”‚
â”‚ å¤šæ¨¡æ€æ‰“åŒ…â”‚         â”‚è§†è§‰ç¼–ç    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚
     â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚Text Encodeâ”‚             â”‚
â”‚(Qwen2.5-VL)â”‚            â”‚
â”‚ è¯­ä¹‰ç†è§£  â”‚             â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
     â”‚                    â”‚
     â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚å¤šæ¨¡æ€Embedâ”‚         â”‚Image Latentsâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚å‡†å¤‡ Latents  â”‚
     â”‚              â”‚
     â”‚â€¢ éšæœºå™ªå£°    â”‚
     â”‚â€¢ å›¾åƒlatents â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ å»å™ªå¾ªç¯50æ­¥ â”‚
     â”‚              â”‚
     â”‚ æ¯æ­¥:        â”‚
     â”‚ â€¢ æ‹¼æ¥latentsâ”‚
     â”‚ â€¢ Transformerâ”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ VAE Decode   â”‚ â†’ ç¼–è¾‘åå›¾åƒ
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ ä¸ƒã€å…³é”®ä»£ç ä½ç½®ç´¢å¼•

| åŠŸèƒ½ | æ–‡ä»¶ä½ç½® | è¡Œå· |
|------|---------|------|
| **åŒè·¯å¾„æ ¸å¿ƒï¼šå¤šæ¨¡æ€ç¼–ç ** | `pipeline_qwenimage_edit.py` | 226-271 |
| **VAE å›¾åƒç¼–ç ** | `pipeline_qwenimage_edit.py` | 395-416 |
| **å»å™ªå¾ªç¯ï¼šLatentæ‹¼æ¥** | `pipeline_qwenimage_edit.py` | 810-828 |
| **Promptæ¨¡æ¿å®šä¹‰** | `pipeline_qwenimage_edit.py` | 213-214 |
| **Processoræ³¨å†Œ** | `pipeline_qwenimage_edit.py` | 187-205 |

---

## âœ… æ€»ç»“

**Qwen-Image-Edit çš„ä¸‰ä¸ªæ ¸å¿ƒåˆ›æ–°**ï¼š

1. â­ **åŒè·¯å¾„è¾“å…¥**ï¼šå›¾åƒåŒæ—¶è¿›å…¥ Qwen2.5-VLï¼ˆè¯­ä¹‰ï¼‰å’Œ VAEï¼ˆå¤–è§‚ï¼‰
2. â­ **Latentæ‹¼æ¥**ï¼šå»å™ªæ—¶æ‹¼æ¥åŸå§‹å›¾åƒå’Œå½“å‰çŠ¶æ€
3. â­ **å¤šæ¨¡æ€ç¼–ç **ï¼šæ–‡æœ¬+å›¾åƒç»Ÿä¸€ç¼–ç ï¼Œç†è§£ç¼–è¾‘æ„å›¾

è¿™ä¸‰ä¸ªåˆ›æ–°ååŒå·¥ä½œï¼Œå®ç°äº†ç²¾ç¡®çš„å›¾åƒç¼–è¾‘èƒ½åŠ›ã€‚

---

## ğŸ¯ å…«ã€CFG (Classifier-Free Guidance) å®ç°è¯¦è§£

### 8.1 CFG åŸç†

CFG é€šè¿‡**å¯¹æ¯”æ¡ä»¶é¢„æµ‹å’Œæ— æ¡ä»¶é¢„æµ‹**æ¥å¢å¼ºç”Ÿæˆè´¨é‡ï¼š

**æ ¸å¿ƒå…¬å¼**ï¼š
```
noise_pred_final = neg_noise_pred + scale * (noise_pred - neg_noise_pred)
```

å…¶ä¸­ï¼š
- `noise_pred`ï¼šæ¡ä»¶é¢„æµ‹ï¼ˆä½¿ç”¨ positive promptï¼‰
- `neg_noise_pred`ï¼šæ— æ¡ä»¶é¢„æµ‹ï¼ˆä½¿ç”¨ negative promptï¼‰
- `scale`ï¼šCFG å¼ºåº¦ï¼ˆé€šå¸¸ä¸º 4.0ï¼‰

**æ„ä¹‰**ï¼šæ”¾å¤§æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹çš„å·®å¼‚ï¼Œä½¿ç”Ÿæˆæ›´ç¬¦åˆ promptã€‚

### 8.2 ä»£ç å®ç°æ­¥éª¤

#### æ­¥éª¤1ï¼šæ£€æŸ¥ CFG æ˜¯å¦å¯ç”¨

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:705-718
has_neg_prompt = negative_prompt is not None or (
    negative_prompt_embeds is not None and negative_prompt_embeds_mask is not None
)

# æ£€æŸ¥æ¡ä»¶
if true_cfg_scale > 1 and not has_neg_prompt:
    logger.warning("CFG scale > 1 but no negative_prompt provided")
elif true_cfg_scale <= 1 and has_neg_prompt:
    logger.warning("negative_prompt provided but CFG scale <= 1")

# â­ å†³å®šæ˜¯å¦å¯ç”¨ CFG
do_true_cfg = true_cfg_scale > 1 and has_neg_prompt
```

**å…³é”®æ¡ä»¶**ï¼š
- âœ… `true_cfg_scale > 1`ï¼ˆé»˜è®¤ 4.0ï¼‰
- âœ… æä¾›äº† `negative_prompt`ï¼ˆå³ä½¿ä¸ºç©ºå­—ç¬¦ä¸² " " ä¹Ÿå¯ä»¥ï¼‰

#### æ­¥éª¤2ï¼šç¼–ç æ¡ä»¶å’Œéæ¡ä»¶ Prompt

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:719-737
# ç¼–ç æ¡ä»¶ promptï¼ˆpositiveï¼‰
prompt_embeds, prompt_embeds_mask = self.encode_prompt(
    image=prompt_image,  # â­ Edit ç‰ˆæœ¬ï¼šåŒæ—¶ç¼–ç å›¾åƒ
    prompt=prompt,
    ...
)

# å¦‚æœå¯ç”¨ CFGï¼Œç¼–ç éæ¡ä»¶ promptï¼ˆnegativeï¼‰
if do_true_cfg:
    negative_prompt_embeds, negative_prompt_embeds_mask = self.encode_prompt(
        image=prompt_image,  # â­ æ³¨æ„ï¼šä½¿ç”¨ç›¸åŒçš„å›¾åƒï¼
        prompt=negative_prompt,
        ...
    )
```

**å…³é”®ç‚¹**ï¼š
- âœ… æ¡ä»¶å’Œéæ¡ä»¶ prompt ä½¿ç”¨**ç›¸åŒçš„è¾“å…¥å›¾åƒ**
- âœ… åŒºåˆ«åœ¨äºæ–‡æœ¬æŒ‡ä»¤ï¼ˆpositive vs negativeï¼‰

#### æ­¥éª¤3ï¼šå»å™ªå¾ªç¯ä¸­çš„åŒé‡é¢„æµ‹

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:815-848
for i, t in enumerate(timesteps):
    # å‡†å¤‡è¾“å…¥ï¼ˆåŒ…å«åŸå§‹å›¾åƒ latentsï¼‰
    latent_model_input = torch.cat([latents, image_latents], dim=1)
    
    # â­ ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼šæ¡ä»¶é¢„æµ‹
    with self.transformer.cache_context("cond"):
        noise_pred = self.transformer(
            hidden_states=latent_model_input,
            timestep=timestep / 1000,
            encoder_hidden_states=prompt_embeds,  # æ¡ä»¶ embeddings
            encoder_hidden_states_mask=prompt_embeds_mask,
            ...
        )[0]
        noise_pred = noise_pred[:, : latents.size(1)]
    
    # â­ ç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­ï¼šéæ¡ä»¶é¢„æµ‹ï¼ˆå¦‚æœå¯ç”¨ CFGï¼‰
    if do_true_cfg:
        with self.transformer.cache_context("uncond"):
            neg_noise_pred = self.transformer(
                hidden_states=latent_model_input,  # â­ ç›¸åŒçš„ latents
                timestep=timestep / 1000,           # â­ ç›¸åŒçš„æ—¶é—´æ­¥
                encoder_hidden_states=negative_prompt_embeds,  # éæ¡ä»¶ embeddings
                encoder_hidden_states_mask=negative_prompt_embeds_mask,
                ...
            )[0]
        neg_noise_pred = neg_noise_pred[:, : latents.size(1)]
```

**å…³é”®ç‚¹**ï¼š
- âœ… ä½¿ç”¨ç›¸åŒçš„ `latent_model_input`ï¼ˆç›¸åŒçš„å»å™ªçŠ¶æ€å’ŒåŸå§‹å›¾åƒï¼‰
- âœ… ä½¿ç”¨ç›¸åŒçš„ `timestep`
- âœ… åŒºåˆ«åœ¨äº `encoder_hidden_states`ï¼ˆæ¡ä»¶ vs éæ¡ä»¶ embeddingsï¼‰

### 8.3 Cache Context æœºåˆ¶

**é—®é¢˜**ï¼šä¸ºä»€ä¹ˆä½¿ç”¨ `cache_context("cond")` å’Œ `cache_context("uncond")`ï¼Ÿ

**ç­”æ¡ˆ**ï¼šè¿™æ˜¯ Transformer çš„**ç¼“å­˜ä¼˜åŒ–æœºåˆ¶**ï¼Œç”¨äºï¼š
- âœ… åŒºåˆ†æ¡ä»¶å’Œéæ¡ä»¶çš„è®¡ç®—ç¼“å­˜
- âœ… é¿å… KV cache æ··æ·†
- âœ… æé«˜è®¡ç®—æ•ˆç‡ï¼ˆå¯ä»¥å¤ç”¨éƒ¨åˆ†è®¡ç®—ç»“æœï¼‰

```python
with self.transformer.cache_context("cond"):
    # æ¡ä»¶é¢„æµ‹ï¼ˆç¼“å­˜æ ‡è®°ä¸º "cond"ï¼‰
    noise_pred = self.transformer(...)

with self.transformer.cache_context("uncond"):
    # éæ¡ä»¶é¢„æµ‹ï¼ˆç¼“å­˜æ ‡è®°ä¸º "uncond"ï¼‰
    neg_noise_pred = self.transformer(...)
```

### 8.4 CFG åˆå¹¶å…¬å¼

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:844
# â­ CFG æ ¸å¿ƒå…¬å¼
comb_pred = neg_noise_pred + true_cfg_scale * (noise_pred - neg_noise_pred)

# å±•å¼€ï¼š
# comb_pred = neg_noise_pred + scale * noise_pred - scale * neg_noise_pred
# comb_pred = (1 - scale) * neg_noise_pred + scale * noise_pred
```

**å…¬å¼è§£æ**ï¼š
- å½“ `scale = 1`ï¼š`comb_pred = noise_pred`ï¼ˆæ— æ¡ä»¶ï¼‰
- å½“ `scale > 1`ï¼šæ”¾å¤§ `(noise_pred - neg_noise_pred)` çš„å·®å¼‚
- å½“ `scale = 4.0`ï¼ˆé»˜è®¤ï¼‰ï¼šå¼ºæ¡ä»¶å¼•å¯¼

**æ•°å­¦æ„ä¹‰**ï¼š
```
å™ªå£°é¢„æµ‹ = æ— æ¡ä»¶é¢„æµ‹ + 4.0 * (æ¡ä»¶é¢„æµ‹ - æ— æ¡ä»¶é¢„æµ‹)
        = -3 * æ— æ¡ä»¶é¢„æµ‹ + 4 * æ¡ä»¶é¢„æµ‹
```

è¿™è¡¨ç¤ºï¼š**æœç€æ¡ä»¶é¢„æµ‹æ–¹å‘ç§»åŠ¨ï¼Œåç¦»æ— æ¡ä»¶é¢„æµ‹**ã€‚

### 8.5 å½’ä¸€åŒ–å¤„ç†ï¼ˆNormalizationï¼‰

```python
# ä½ç½®: pipelines/qwenimage/pipeline_qwenimage_edit.py:846-848
# â­ å½’ä¸€åŒ–å¤„ç†ï¼šä¿æŒé¢„æµ‹çš„å°ºåº¦ä¸€è‡´æ€§
cond_norm = torch.norm(noise_pred, dim=-1, keepdim=True)
noise_norm = torch.norm(comb_pred, dim=-1, keepdim=True)
noise_pred = comb_pred * (cond_norm / noise_norm)
```

**ç›®çš„**ï¼š
- âœ… ä¿æŒ `comb_pred` ä¸ `noise_pred` çš„**èŒƒæ•°ä¸€è‡´**
- âœ… é˜²æ­¢ CFG å¯¼è‡´é¢„æµ‹å°ºåº¦è¿‡å¤§
- âœ… æé«˜æ•°å€¼ç¨³å®šæ€§

**è®¡ç®—æ–¹å¼**ï¼š
- è®¡ç®—æ¡ä»¶é¢„æµ‹çš„ L2 èŒƒæ•°ï¼š`||noise_pred||`
- è®¡ç®—åˆå¹¶é¢„æµ‹çš„ L2 èŒƒæ•°ï¼š`||comb_pred||`
- ç¼©æ”¾åˆå¹¶é¢„æµ‹ï¼š`comb_pred * (||noise_pred|| / ||comb_pred||)`

### 8.6 å®Œæ•´ CFG æµç¨‹å›¾

```
å»å™ªæ­¥éª¤ t
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‡†å¤‡ Latent Model Input            â”‚
â”‚ â€¢ latents (å½“å‰å»å™ªçŠ¶æ€)            â”‚
â”‚ â€¢ image_latents (åŸå§‹å›¾åƒ)          â”‚
â”‚ â†’ latent_model_input               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                          â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ æ¡ä»¶é¢„æµ‹è·¯å¾„    â”‚        â”‚ éæ¡ä»¶é¢„æµ‹è·¯å¾„  â”‚
       â”‚                â”‚        â”‚                â”‚
       â”‚ cache_context  â”‚        â”‚ cache_context  â”‚
       â”‚ ("cond")       â”‚        â”‚ ("uncond")     â”‚
       â”‚                â”‚        â”‚                â”‚
       â”‚ Transformer:    â”‚        â”‚ Transformer:   â”‚
       â”‚ â€¢ prompt_embeds â”‚        â”‚ â€¢ neg_embeds   â”‚
       â”‚ â€¢ latent_input  â”‚        â”‚ â€¢ latent_input â”‚
       â”‚ â€¢ timestep      â”‚        â”‚ â€¢ timestep     â”‚
       â”‚                â”‚        â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
               â–¼                          â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ noise_pred   â”‚           â”‚ neg_noise_predâ”‚
       â”‚ (æ¡ä»¶é¢„æµ‹)   â”‚           â”‚ (éæ¡ä»¶é¢„æµ‹) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ CFG åˆå¹¶å…¬å¼          â”‚
              â”‚                       â”‚
              â”‚ comb_pred =           â”‚
              â”‚   neg_pred +          â”‚
              â”‚   scale *             â”‚
              â”‚   (pred - neg_pred)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ å½’ä¸€åŒ–å¤„ç†            â”‚
              â”‚                       â”‚
              â”‚ norm_cond = ||pred||  â”‚
              â”‚ norm_comb = ||comb||  â”‚
              â”‚ final = comb *        â”‚
              â”‚        (norm_cond /   â”‚
              â”‚         norm_comb)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Scheduler Step        â”‚
              â”‚                       â”‚
              â”‚ latents =             â”‚
              â”‚   scheduler.step(     â”‚
              â”‚     final_pred, ...)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.7 CFG å…³é”®ä»£ç ä½ç½®æ€»ç»“

| åŠŸèƒ½ | ä»£ç ä½ç½® | å…³é”®ä»£ç  |
|------|---------|---------|
| **CFG å¯ç”¨æ£€æŸ¥** | `pipeline_qwenimage_edit.py:705-718` | `do_true_cfg = true_cfg_scale > 1 and has_neg_prompt` |
| **éæ¡ä»¶ç¼–ç ** | `pipeline_qwenimage_edit.py:728-737` | `encode_prompt(image, negative_prompt, ...)` |
| **æ¡ä»¶é¢„æµ‹** | `pipeline_qwenimage_edit.py:816-828` | `transformer(..., prompt_embeds)` |
| **éæ¡ä»¶é¢„æµ‹** | `pipeline_qwenimage_edit.py:831-843` | `transformer(..., negative_prompt_embeds)` |
| **CFG åˆå¹¶** | `pipeline_qwenimage_edit.py:844` | `comb_pred = neg_pred + scale * (pred - neg_pred)` |
| **å½’ä¸€åŒ–** | `pipeline_qwenimage_edit.py:846-848` | `comb_pred * (cond_norm / comb_norm)` |

### 8.8 CFG åœ¨ Edit ç‰ˆæœ¬çš„ç‰¹æ®Šæ€§

**ä¸åŸç‰ˆå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | åŸç‰ˆ Qwen-Image | Edit ç‰ˆæœ¬ |
|------|----------------|-----------|
| **å›¾åƒè¾“å…¥** | âŒ æ—  | âœ… **æœ‰**ï¼ˆåŒæ—¶ç”¨äºæ¡ä»¶å’Œéæ¡ä»¶ï¼‰ |
| **Prompt ç¼–ç ** | ä»…æ–‡æœ¬ | âœ… **æ–‡æœ¬+å›¾åƒ**ï¼ˆå¤šæ¨¡æ€ï¼‰ |
| **CFG å…¬å¼** | âœ… ç›¸åŒ | âœ… ç›¸åŒ |
| **å½’ä¸€åŒ–** | âœ… ç›¸åŒ | âœ… ç›¸åŒ |
| **Cache æœºåˆ¶** | âœ… ç›¸åŒ | âœ… ç›¸åŒ |

**Edit ç‰ˆæœ¬çš„åˆ›æ–°**ï¼š
- âœ… æ¡ä»¶å’Œéæ¡ä»¶çš„ prompt embeddings éƒ½åŒ…å«**å›¾åƒç†è§£**
- âœ… è¿™æ„å‘³ç€ CFG æ˜¯åœ¨"ç†è§£å›¾åƒ"çš„åŸºç¡€ä¸Šè¿›è¡Œå¼•å¯¼
- âœ… æ›´ç²¾ç¡®åœ°æ§åˆ¶ç¼–è¾‘æ–¹å‘å’Œå¼ºåº¦

**ç¤ºä¾‹**ï¼š
```python
# æ¡ä»¶ promptï¼ˆpositiveï¼‰
prompt = "Change the rabbit's color to purple"
â†’ ç¼–ç ä¸ºï¼šå›¾åƒè¯­ä¹‰ + "ç´«è‰²å…”å­"çš„æŒ‡ä»¤

# éæ¡ä»¶ promptï¼ˆnegativeï¼‰
negative_prompt = " "
â†’ ç¼–ç ä¸ºï¼šå›¾åƒè¯­ä¹‰ + ç©ºæŒ‡ä»¤ï¼ˆç†è§£ä¸º"ä¿æŒåŸæ ·"ï¼‰

# CFG ä½œç”¨ï¼šæ”¾å¤§"å˜ä¸ºç´«è‰²"ä¸"ä¿æŒåŸæ ·"çš„å·®å¼‚
```

### 8.9 CFG Scale å‚æ•°å½±å“

| Scale å€¼ | æ•ˆæœ | å…¬å¼è§£æ |
|----------|------|---------|
| `1.0` | æ—  CFG | `comb_pred = noise_pred` |
| `2.0` | å¼±å¼•å¯¼ | `comb_pred = -1 * neg_pred + 2 * pred` |
| `4.0` (é»˜è®¤) | å¼ºå¼•å¯¼ | `comb_pred = -3 * neg_pred + 4 * pred` |
| `7.5+` | è¿‡åº¦å¼•å¯¼ | å¯èƒ½å¯¼è‡´ä¸è‡ªç„¶çš„ç»“æœ |

**å»ºè®®å€¼**ï¼š`true_cfg_scale = 4.0`ï¼ˆé»˜è®¤ï¼‰ï¼Œæ ¹æ®ä»»åŠ¡è°ƒæ•´ã€‚

---

**æ€»ç»“**ï¼šQwen-Image-Edit çš„ CFG å®ç°é‡‡ç”¨æ ‡å‡† CFG å…¬å¼ï¼Œä½†åˆ›æ–°åœ¨äº**æ¡ä»¶å’Œéæ¡ä»¶éƒ½åŒ…å«å¤šæ¨¡æ€ï¼ˆå›¾åƒ+æ–‡æœ¬ï¼‰ç†è§£**ï¼Œä½¿å¼•å¯¼æ›´ç²¾ç¡®ã€æ›´ç¬¦åˆç¼–è¾‘æ„å›¾ã€‚

