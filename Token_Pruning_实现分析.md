# Token Pruning åœ¨ Qwen-Image-Edit ä¸­çš„å®ç°åˆ†æ

## ğŸ¯ ç›®æ ‡æ–¹æ¡ˆ

**ç­–ç•¥**ï¼š
- æ­¥éª¤ 1, 3ï¼šå®Œæ•´è®¡ç®—æ‰€æœ‰ tokens
- æ­¥éª¤ 2ï¼šé‡ç”¨æ­¥éª¤ 1 çš„ image tokens hidden states
- æ­¥éª¤ 4ï¼šé‡ç”¨æ­¥éª¤ 3 çš„ image tokens hidden states

**é¢„æœŸåŠ é€Ÿ**ï¼šçº¦ 40-50%ï¼ˆè·³è¿‡ 2/4 æ­¥éª¤çš„ image tokens è®¡ç®—ï¼‰

---

## ğŸ” å…³é”®æŠ€æœ¯ç‚¹åˆ†æ

### 1. Token çš„å®šä¹‰å’Œä½ç½®

#### åœ¨ Pipeline å±‚é¢

```python
# pipelines/qwenimage/pipeline_qwenimage_edit.py:810-812
latent_model_input = latents  # [B, L1, C]
if image_latents is not None:
    latent_model_input = torch.cat([latents, image_latents], dim=1)
    # å½¢çŠ¶: [B, L1+L2, C]
    # L1: å»å™ª tokens æ•°é‡
    # L2: å›¾åƒ tokens æ•°é‡
```

#### åœ¨ Transformer å±‚é¢

```python
# models/transformers/transformer_qwenimage.py:618
hidden_states = self.img_in(hidden_states)  # [B, L1+L2, inner_dim]

# ç»è¿‡ 60 å±‚ blocks
for block in self.transformer_blocks:
    encoder_hidden_states, hidden_states = block(
        hidden_states=hidden_states,  # [B, L1+L2, inner_dim]
        ...
    )
```

**å…³é”®**ï¼šéœ€è¦åœ¨æ¯ä¸ª block ä¸­åˆ†ç¦» L1 å’Œ L2 éƒ¨åˆ†ã€‚

---

## ğŸ”¬ å®ç°æ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆ Aï¼šåœ¨ TransformerBlock å±‚é¢ä¿®æ”¹ï¼ˆæ¨èï¼‰

#### ä¿®æ”¹ä½ç½®

```python
# models/transformers/transformer_qwenimage.py:411-476
class QwenImageTransformerBlock(nn.Module):
    def forward(
        self,
        hidden_states: torch.Tensor,  # [B, L1+L2, D]
        encoder_hidden_states: torch.Tensor,
        encoder_hidden_states_mask: torch.Tensor,
        temb: torch.Tensor,
        image_rotary_emb,
        joint_attention_kwargs,
    ):
```

#### ä¿®æ”¹ç­–ç•¥

```python
def forward_with_pruning(self, hidden_states, ...):
    # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦ pruning
    if should_prune and cached_image_hidden is not None:
        L_denoise = denoise_token_length
        
        # 2. åˆ†ç¦» tokens
        denoise_hidden = hidden_states[:, :L_denoise]  # å»å™ªéƒ¨åˆ†
        image_hidden = hidden_states[:, L_denoise:]     # å›¾åƒéƒ¨åˆ†
        
        # 3. åªå¯¹å»å™ªéƒ¨åˆ†åšå®Œæ•´è®¡ç®—
        # å›¾åƒéƒ¨åˆ†ä½¿ç”¨ç¼“å­˜å‚ä¸è®¡ç®—ï¼ˆæä¾› K, Vï¼‰
        
        # 4. è®¡ç®—æ—¶çš„ç­–ç•¥
        # å›¾åƒ tokens:
        #   - Q: ä¸è®¡ç®—ï¼ˆåæ­£ä¸ç”¨ï¼‰
        #   - K, V: ä½¿ç”¨ç¼“å­˜çš„ hidden state è®¡ç®—ï¼ˆä¾›å»å™ª queryï¼‰
        #   - MLP: ä¸è®¡ç®—ï¼ˆåæ­£æœ€åä¸ç”¨ï¼‰
        
        # å»å™ª tokens:
        #   - Q, K, V: æ­£å¸¸è®¡ç®—
        #   - MLP: æ­£å¸¸è®¡ç®—
```

---

### æ–¹æ¡ˆ Bï¼šåœ¨æ³¨æ„åŠ›å±‚é¢ä¿®æ”¹ï¼ˆæœ€ä¼˜ä½†å¤æ‚ï¼‰

#### ä¿®æ”¹ä½ç½®

```python
# models/transformers/transformer_qwenimage.py:250-360
class QwenDoubleStreamAttnProcessor2_0:
    def __call__(self, attn, hidden_states, encoder_hidden_states, ...):
```

#### æ ¸å¿ƒé€»è¾‘

```python
def attention_with_pruning(attn, hidden_states, ...):
    L_denoise = pruning_context.denoise_token_length
    
    # åˆ†ç¦»å»å™ªå’Œå›¾åƒ tokens
    denoise_hidden = hidden_states[:, :L_denoise]
    image_hidden = hidden_states[:, L_denoise:]  # è¿™æ˜¯ç¼“å­˜çš„
    
    # === QKV æŠ•å½± ===
    # å»å™ª tokens: å®Œæ•´æŠ•å½±
    denoise_q = attn.to_q(denoise_hidden)
    denoise_k = attn.to_k(denoise_hidden)
    denoise_v = attn.to_v(denoise_hidden)
    
    # å›¾åƒ tokens: åªæŠ•å½± K, Vï¼ˆä¸æŠ•å½± Qï¼Œå› ä¸ºä¸éœ€è¦æŸ¥è¯¢ï¼‰
    image_k = attn.to_k(image_hidden)  # â­ ä½¿ç”¨ç¼“å­˜çš„ hidden state
    image_v = attn.to_v(image_hidden)  # â­ ä½¿ç”¨ç¼“å­˜çš„ hidden state
    # ä¸è®¡ç®— image_qï¼ˆèŠ‚çœï¼‰
    
    # æ–‡æœ¬ tokens: æ­£å¸¸å¤„ç†
    txt_q = attn.to_add_q(encoder_hidden_states)
    txt_k = attn.to_add_k(encoder_hidden_states)
    txt_v = attn.to_add_v(encoder_hidden_states)
    
    # === æ‹¼æ¥å¹¶è®¡ç®—æ³¨æ„åŠ› ===
    joint_query = torch.cat([txt_q, denoise_q], dim=1)  # ä¸åŒ…å« image_q
    joint_key = torch.cat([txt_k, image_k, denoise_k], dim=1)
    joint_value = torch.cat([txt_v, image_v, denoise_v], dim=1)
    
    # è®¡ç®—æ³¨æ„åŠ›ï¼ˆimage tokens æä¾› K,V ä½†ä¸ä¸»åŠ¨æŸ¥è¯¢ï¼‰
    attention_output = dispatch_attention_fn(joint_query, joint_key, joint_value, ...)
    
    # === åˆ†ç¦»è¾“å‡º ===
    txt_output = attention_output[:, :L_txt]
    denoise_output = attention_output[:, L_txt:]
    image_output = ä½¿ç”¨ç¼“å­˜  # ä¸æ›´æ–°
    
    # === MLP å¤„ç† ===
    # åªå¯¹å»å™ª tokens è®¡ç®— MLP
    denoise_mlp_output = self.img_mlp(denoise_modulated)
    # å›¾åƒ tokens è·³è¿‡ MLP
```

---

## âš ï¸ å®ç°æŒ‘æˆ˜

### æŒ‘æˆ˜ 1ï¼šç´¢å¼•ç®¡ç†çš„å¤æ‚æ€§

```python
# éœ€è¦åœ¨æ•´ä¸ª forward pass ä¸­ç»´æŠ¤ç´¢å¼•
L_denoise = ?  # å¦‚ä½•ä¼ é€’åˆ°æ¯ä¸ª blockï¼Ÿ
L_image = ?

# æ–¹æ¡ˆï¼šé€šè¿‡ attention_kwargs ä¼ é€’
attention_kwargs = {
    "denoise_token_length": L_denoise,
    "enable_pruning": True,
    "cached_hidden": cached_states
}
```

---

### æŒ‘æˆ˜ 2ï¼šç¼“å­˜çš„æ—¶æœºå’Œä½ç½®

```python
# é—®é¢˜ï¼šåœ¨å“ªé‡Œç¼“å­˜ï¼Ÿ

# é€‰é¡¹ Aï¼šåœ¨ block è¾“å‡ºå¤„ç¼“å­˜
# æ¯ä¸ª block éƒ½éœ€è¦ç¼“å­˜ â†’ 60 å±‚ Ã— 2 ä¸ªç¼“å­˜ç‚¹ = 120 ä¸ªç¼“å­˜

# é€‰é¡¹ Bï¼šåªåœ¨æœ€åä¸€å±‚ç¼“å­˜
# åªç¼“å­˜æœ€ç»ˆçš„ hidden states
# ä½†æ¯ä¸ª block éƒ½éœ€è¦å®ƒï¼Œå¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸åŒ¹é…
```

**æˆ‘çš„å»ºè®®**ï¼šåœ¨æ¯ä¸ª block éƒ½ç¼“å­˜ï¼ˆè™½ç„¶å†…å­˜å¼€é”€å¤§ï¼Œä½†æ­£ç¡®æ€§é«˜ï¼‰

---

### æŒ‘æˆ˜ 3ï¼šæ³¨æ„åŠ›è®¡ç®—çš„ä¸å¯¹ç§°æ€§

```python
# é—®é¢˜ï¼šimage tokens ä¸ç”Ÿæˆ Qï¼Œä½†å‚ä¸ K,V
# è¿™ä¼šå¯¼è‡´ attention mask çš„ä¸å¯¹ç§°

# åŸå§‹ï¼š
joint_query = [txt_q, img_q, denoise_q]  # å½¢çŠ¶: [B, L_txt+L_img+L_denoise, H, D]
joint_key = [txt_k, img_k, denoise_k]    # å½¢çŠ¶: [B, L_txt+L_img+L_denoise, H, D]

# Pruning åï¼š
joint_query = [txt_q, denoise_q]         # å½¢çŠ¶: [B, L_txt+L_denoise, H, D]  âš ï¸ ç¼©çŸ­äº†
joint_key = [txt_k, img_k, denoise_k]    # å½¢çŠ¶: [B, L_txt+L_img+L_denoise, H, D]

# æ³¨æ„åŠ›çŸ©é˜µå½¢çŠ¶ä¸åŒ¹é…ï¼
# Q: [B, H, L_txt+L_denoise, D]
# K: [B, H, L_txt+L_img+L_denoise, D]
# QK^T: [B, H, L_txt+L_denoise, L_txt+L_img+L_denoise]  â† è¿™æ˜¯å¯ä»¥çš„ï¼
```

**å¥½æ¶ˆæ¯**ï¼šæ³¨æ„åŠ›å¯ä»¥å¤„ç†ä¸å¯¹ç§°çš„ Q å’Œ Kï¼

---

## ğŸ’¡ ç®€åŒ–å®ç°æ–¹æ¡ˆ

è€ƒè™‘åˆ°å¤æ‚æ€§ï¼Œæˆ‘å»ºè®®åˆ†ä¸¤é˜¶æ®µï¼š

### é˜¶æ®µ 1ï¼šç®€åŒ–ç‰ˆï¼ˆåªè·³è¿‡ MLPï¼‰â­ å…ˆå®ç°è¿™ä¸ª

```python
def forward_pruning_v1(self, hidden_states, ...):
    """
    åªè·³è¿‡ image tokens çš„ MLPï¼Œä¿ç•™æ³¨æ„åŠ›è®¡ç®—
    """
    L_denoise = denoise_token_length
    
    # === æ³¨æ„åŠ›ï¼šæ­£å¸¸è®¡ç®—ï¼ˆæ‰€æœ‰ tokensï¼‰===
    img_attn_output, txt_attn_output = self.attn(...)
    hidden_states = hidden_states + img_gate1 * img_attn_output
    
    # === MLPï¼šåªè®¡ç®—å»å™ª tokens ===
    if should_prune:
        # åªå¯¹å»å™ªéƒ¨åˆ†è®¡ç®— MLP
        denoise_hidden = hidden_states[:, :L_denoise]
        denoise_normed = self.img_norm2(denoise_hidden)
        denoise_modulated, gate = self._modulate(denoise_normed, img_mod2)
        denoise_mlp = self.img_mlp(denoise_modulated)
        denoise_hidden = denoise_hidden + gate * denoise_mlp
        
        # å›¾åƒéƒ¨åˆ†ï¼šé‡ç”¨ç¼“å­˜ï¼ˆè·³è¿‡ MLPï¼‰
        image_hidden = cached_image_hidden[:, L_denoise:]
        
        # åˆå¹¶
        hidden_states = torch.cat([denoise_hidden, image_hidden], dim=1)
    else:
        # æ­£å¸¸è®¡ç®—
        img_normed2 = self.img_norm2(hidden_states)
        img_modulated2, img_gate2 = self._modulate(img_normed2, img_mod2)
        img_mlp_output = self.img_mlp(img_modulated2)
        hidden_states = hidden_states + img_gate2 * img_mlp_output
    
    return encoder_hidden_states, hidden_states
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®ç°ç®€å•
- âœ… æ³¨æ„åŠ›å®Œæ•´ï¼ˆä¿è¯ä¿¡æ¯æµåŠ¨ï¼‰
- âœ… åªä¼˜åŒ– MLPï¼ˆçº¦ 30% åŠ é€Ÿï¼‰

---

### é˜¶æ®µ 2ï¼šå®Œæ•´ç‰ˆï¼ˆæ³¨æ„åŠ› + MLPï¼‰

å¦‚æœé˜¶æ®µ 1 æ•ˆæœå¥½ï¼Œå†å®ç°å®Œæ•´ç‰ˆã€‚

---

## ğŸ“Š é¢„æœŸæ•ˆæœåˆ†æ

### è®¡ç®—é‡åˆ†è§£ï¼ˆæ¯ä¸ª Blockï¼‰

| ç»„ä»¶ | å»å™ª tokens | å›¾åƒ tokens | æ€»è®¡ |
|------|-----------|-----------|------|
| **Q æŠ•å½±** | L1 Ã— DÂ² | L2 Ã— DÂ² | (L1+L2) Ã— DÂ² |
| **K æŠ•å½±** | L1 Ã— DÂ² | L2 Ã— DÂ² | (L1+L2) Ã— DÂ² |
| **V æŠ•å½±** | L1 Ã— DÂ² | L2 Ã— DÂ² | (L1+L2) Ã— DÂ² |
| **æ³¨æ„åŠ›** | - | - | O(LÂ² Ã— D) |
| **MLP** | L1 Ã— 4DÂ² | L2 Ã— 4DÂ² | (L1+L2) Ã— 4DÂ² |

### ç®€åŒ–ç‰ˆåŠ é€Ÿï¼ˆåªè·³è¿‡ MLPï¼‰

- è·³è¿‡æ­¥éª¤ 2, 4 çš„ image MLP
- èŠ‚çœï¼š2 Ã— 60å±‚ Ã— L2 Ã— 4DÂ² Ã— 2æ­¥ = **çº¦ 30-40%**

### å®Œæ•´ç‰ˆåŠ é€Ÿï¼ˆè·³è¿‡ Q + MLPï¼‰

- è·³è¿‡æ­¥éª¤ 2, 4 çš„ image Q æŠ•å½±å’Œ MLP
- èŠ‚çœï¼š2 Ã— 60å±‚ Ã— L2 Ã— (DÂ² + 4DÂ²) Ã— 2æ­¥ = **çº¦ 40-50%**

---

## âš ï¸ æˆ‘ä»ç„¶æ‹…å¿ƒçš„é—®é¢˜

### 1. **Image Tokens çš„è§’è‰²æ¼”åŒ–**

åœ¨ Edit ä»»åŠ¡ä¸­ï¼Œimage tokens ä¸ä»…æ˜¯é™æ€å‚è€ƒï¼š

```python
# æ­¥éª¤ 1: é«˜å™ªå£°æ°´å¹³
å»å™ª tokens: [å¤§é‡å™ªå£°]
å›¾åƒ tokens: æä¾›"è¿™æ˜¯ä»€ä¹ˆç‰©ä½“"çš„è¯­ä¹‰å¼•å¯¼

# æ­¥éª¤ 2-3: ä¸­ç­‰å™ªå£°
å»å™ª tokens: [éƒ¨åˆ†æ¸…æ™°]
å›¾åƒ tokens: æä¾›"ç»†èŠ‚çº¹ç†"çš„å¤–è§‚å¼•å¯¼

# æ­¥éª¤ 4: ä½å™ªå£°
å»å™ª tokens: [åŸºæœ¬æ¸…æ™°]
å›¾åƒ tokens: æä¾›"ç²¾ç¡®å¯¹é½"çš„å‚è€ƒ
```

**é—®é¢˜**ï¼šä¸åŒæ­¥éª¤éœ€è¦ image tokens çš„ä¸åŒ"è§†è§’"ã€‚å†»ç»“å¯èƒ½å¯¼è‡´å¼•å¯¼ä¸åŒ¹é…ã€‚

---

### 2. **åŒæµæ¶æ„çš„è€¦åˆæ€§**

```python
# QwenImageTransformerBlock ä¸­
# å›¾åƒæµå’Œæ–‡æœ¬æµæ˜¯è€¦åˆçš„
encoder_hidden_states, hidden_states = block(...)

# æ–‡æœ¬æµä¼šå½±å“å›¾åƒæµï¼Œå›¾åƒæµä¼šå½±å“æ–‡æœ¬æµ
# å†»ç»“å›¾åƒ tokens å¯èƒ½ç ´åè¿™ç§å¹³è¡¡
```

---

### 3. **å®éªŒéªŒè¯çš„å¿…è¦æ€§**

å»ºè®®å¯¹æ¯”ä¸‰ä¸ªç‰ˆæœ¬ï¼š

```python
# A. Baselineï¼ˆæ—  pruningï¼‰
python 5_lightning_with_token_pruning.py --no-pruning

# B. ç®€åŒ–ç‰ˆï¼ˆåªè·³è¿‡ MLPï¼‰
python 5_lightning_with_token_pruning.py --pruning-mode mlp

# C. å®Œæ•´ç‰ˆï¼ˆè·³è¿‡ Q + MLPï¼‰
python 5_lightning_with_token_pruning.py --pruning-mode full
```

åˆ†åˆ«æµ‹é‡ï¼š
- æ¨ç†æ—¶é—´
- PSNR / SSIMï¼ˆä¸æ—  pruning å¯¹æ¯”ï¼‰
- è§†è§‰è´¨é‡

---

## ğŸ¯ æˆ‘çš„å®ç°å»ºè®®

### ç¬¬ä¸€æ­¥ï¼šæœ€å°å¯è¡Œå®ç°ï¼ˆMVPï¼‰

åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•ç‰ˆæœ¬ï¼š

```python
# ä¼ªä»£ç 
class PrunableQwenImageEditPipeline:
    def __call__(self, ...):
        for i, t in enumerate(timesteps):
            if i in [0, 2]:  # æ­¥éª¤ 1, 3
                # å®Œæ•´è®¡ç®—
                output = transformer(latent_model_input, ...)
                # ç¼“å­˜ image tokens çš„è¾“å‡º
                cache[i] = output[:, denoise_length:]
            else:  # æ­¥éª¤ 2, 4
                # ä½¿ç”¨ç¼“å­˜
                denoise_input = latent_model_input[:, :denoise_length]
                cached_image = cache[i-1]
                
                # åªè®¡ç®—å»å™ªéƒ¨åˆ†ï¼ˆä½†è¿™éœ€è¦ä¿®æ”¹ transformer å†…éƒ¨ï¼‰
                output_denoise = transformer(
                    denoise_input,
                    cached_image_for_attention=cached_image,
                    ...
                )
```

**é—®é¢˜**ï¼šè¿™éœ€è¦ transformer æ”¯æŒåˆ†ç¦»è®¡ç®—ï¼Œç›®å‰ä¸æ”¯æŒã€‚

---

### ç¬¬äºŒæ­¥ï¼šMonkey Patch Transformer

åˆ›å»ºä¸€ä¸ª wrapper æ¥æ‹¦æˆªå’Œä¿®æ”¹è®¡ç®—ï¼š

```python
def create_pruning_wrapper(original_block, denoise_len, cache_dict):
    """
    åˆ›å»ºå¸¦ pruning çš„ block wrapper
    """
    def wrapped_forward(hidden_states, step_idx, ...):
        if step_idx in [1, 3]:  # éœ€è¦ prune
            # åˆ†ç¦»
            denoise_h = hidden_states[:, :denoise_len]
            image_h = cache_dict[step_idx - 1]  # ä½¿ç”¨ä¸Šä¸€æ­¥ç¼“å­˜
            
            # âš ï¸ è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼š
            # åŸå§‹ forward æœŸæœ›å®Œæ•´çš„ hidden_states
            # æˆ‘ä»¬éœ€è¦"æ¬ºéª—"å®ƒï¼Œè®©å®ƒä»¥ä¸ºåœ¨å¤„ç†å®Œæ•´è¾“å…¥
            # ä½†å®é™…ä¸Š image éƒ¨åˆ†æ˜¯ç¼“å­˜çš„
            
            # ç­–ç•¥ï¼šæ„é€ ä¸€ä¸ªå‡çš„å®Œæ•´è¾“å…¥
            fake_full_hidden = torch.cat([denoise_h, image_h], dim=1)
            
            # è°ƒç”¨åŸå§‹ forward
            output = original_block(fake_full_hidden, ...)
            
            # åªå–å»å™ªéƒ¨åˆ†çš„è¾“å‡º
            output_denoise = output[:, :denoise_len]
            # å›¾åƒéƒ¨åˆ†ç»§ç»­ä½¿ç”¨ç¼“å­˜
            output_final = torch.cat([output_denoise, image_h], dim=1)
            
            return output_final
        else:
            # å®Œæ•´è®¡ç®—
            output = original_block(hidden_states, ...)
            # ç¼“å­˜ image éƒ¨åˆ†
            cache_dict[step_idx] = output[:, denoise_len:].clone()
            return output
    
    return wrapped_forward
```

---

## ğŸš§ å®ç°çš„æ ¸å¿ƒéš¾ç‚¹

### éš¾ç‚¹ 1ï¼šåœ¨ Block å†…éƒ¨åŒºåˆ† denoise å’Œ image tokens

**é—®é¢˜**ï¼šBlock ä¸çŸ¥é“è¾“å…¥çš„å“ªéƒ¨åˆ†æ˜¯ denoiseï¼Œå“ªéƒ¨åˆ†æ˜¯ imageã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡ `attention_kwargs` ä¼ é€’å…ƒæ•°æ®

```python
attention_kwargs = {
    "denoise_token_length": L_denoise,
    "current_step": i,
    "enable_pruning": True,
    "image_cache": cache_dict
}
```

---

### éš¾ç‚¹ 2ï¼š60 å±‚ Block çš„ç¼“å­˜ç®¡ç†

**é—®é¢˜**ï¼šæ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¸åŒï¼Œå¦‚ä½•ç¼“å­˜ï¼Ÿ

**æ–¹æ¡ˆ A**ï¼šç¼“å­˜æ¯ä¸€å±‚çš„ image tokens
```python
layer_caches = {
    0: [layer0_image_hidden, layer1_image_hidden, ..., layer59_image_hidden],
    2: [layer0_image_hidden, layer1_image_hidden, ..., layer59_image_hidden],
}
```
å†…å­˜å¼€é”€ï¼š60å±‚ Ã— 2ç¼“å­˜ Ã— L2 Ã— D Ã— 4bytes â‰ˆ å‡ ç™¾MB

**æ–¹æ¡ˆ B**ï¼šåªç¼“å­˜è¾“å…¥å’Œè¾“å‡º
- é—®é¢˜ï¼šä¸­é—´å±‚çš„ä¿¡æ¯ä¸åŒ¹é…

**å»ºè®®**ï¼šä½¿ç”¨æ–¹æ¡ˆ Aï¼Œå†…å­˜å¼€é”€å¯æ¥å—

---

## ğŸ“ å®Œæ•´å®ç°è·¯çº¿å›¾

### ç¬¬ 1 é˜¶æ®µï¼šå‡†å¤‡å·¥ä½œ

1. âœ… åˆ›å»º TokenPruningContext ç±»
2. âœ… åˆ›å»ºè‡ªå®šä¹‰ Pipeline ç±»
3. â³ ä¿®æ”¹ Transformer Block forward

### ç¬¬ 2 é˜¶æ®µï¼šæ ¸å¿ƒå®ç°

1. ä¿®æ”¹ `QwenImageTransformerBlock.forward`
2. æ·»åŠ ç¼“å­˜ç®¡ç†é€»è¾‘
3. åœ¨ pipeline çš„å»å™ªå¾ªç¯ä¸­é›†æˆ

### ç¬¬ 3 é˜¶æ®µï¼šæµ‹è¯•éªŒè¯

1. æµ‹è¯•æ¨ç†é€Ÿåº¦
2. æµ‹è¯•è¾“å‡ºè´¨é‡
3. å¯¹æ¯”å®éªŒ

---

## ğŸ¤” æˆ‘çš„å»ºè®®ï¼ˆè¯·ç¡®è®¤ï¼‰

é‰´äºå®ç°å¤æ‚åº¦ï¼Œæˆ‘å»ºè®®ï¼š

**æ–¹æ¡ˆ Aï¼šå®Œæ•´ä½†æ­£ç¡®çš„å®ç°**ï¼ˆæˆ‘å¼€å§‹å®ç°äº†ï¼‰
- éœ€è¦æ·±åº¦ä¿®æ”¹ Transformer å†…éƒ¨
- å®ç°å¤æ‚ï¼Œä½†æ•ˆæœå¯æ§
- é¢„è®¡éœ€è¦ 500-800 è¡Œä»£ç 

**æ–¹æ¡ˆ Bï¼šç®€åŒ–ç‰ˆå…ˆéªŒè¯**
- åªåœ¨ pipeline å±‚é¢åš token åˆ†ç¦»
- ä½¿ç”¨ç®€å•çš„ monkey patch
- å¿«é€ŸéªŒè¯æƒ³æ³•ï¼Œç„¶åå†ä¼˜åŒ–

**æ‚¨å¸Œæœ›æˆ‘ç»§ç»­å®Œæ•´å®ç°ï¼Œè¿˜æ˜¯å…ˆåšä¸€ä¸ªç®€åŒ–ç‰ˆå¿«é€Ÿæµ‹è¯•ï¼Ÿ** 

å¦å¤–ï¼Œæˆ‘æ‹…å¿ƒçš„æ˜¯ï¼š**åœ¨ 4 æ­¥æ¨ç†ä¸­ï¼Œæ¯æ­¥çš„ä½œç”¨éƒ½å¾ˆå…³é”®ï¼Œpruning 2 æ­¥å¯èƒ½å½±å“è¾ƒå¤§**ã€‚å»ºè®®å…ˆå®ç°èƒ½å¯¹æ¯”çš„ç‰ˆæœ¬ï¼Œæµ‹é‡è´¨é‡æŸå¤±ã€‚
