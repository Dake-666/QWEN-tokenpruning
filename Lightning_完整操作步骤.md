# Qwen-Image-Edit Lightning å®Œæ•´æ“ä½œæ­¥éª¤

## ğŸ¯ å…³é”®å‘ç°

æ ¹æ®å®˜æ–¹ Hugging Face æ–‡æ¡£ï¼š
- **Lightning æ˜¯ LoRA æƒé‡**ï¼Œä¸æ˜¯å®Œæ•´æ¨¡å‹
- éœ€è¦å…ˆåŠ è½½åŸºç¡€æ¨¡å‹ `Qwen/Qwen-Image-Edit`
- ç„¶åä½¿ç”¨ `load_lora_weights()` åŠ è½½ Lightning LoRA
- ä½¿ç”¨ `fuse_lora()` å¯ä»¥å°† LoRA æ°¸ä¹…èåˆåˆ°æƒé‡ä¸­

---

## ğŸ“š å®˜æ–¹æ–‡æ¡£

- **Hugging Face**: https://huggingface.co/lightx2v/Qwen-Image-Lightning
- **åŸºç¡€æ¨¡å‹**: https://huggingface.co/Qwen/Qwen-Image-Edit
- **å‚è€ƒä»“åº“**: https://github.com/huggingface/diffusers

---

## ğŸ”§ å‡†å¤‡å·¥ä½œ

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£…æœ€æ–°ç‰ˆ diffusersï¼ˆä» GitHubï¼‰
pip install git+https://github.com/huggingface/diffusers

# å®‰è£…å…¶ä»–ä¾èµ–
pip install torch transformers accelerate pillow safetensors
```

### 2. ç¡®è®¤ç¯å¢ƒ

```bash
python -c "import diffusers; print(f'diffusers ç‰ˆæœ¬: {diffusers.__version__}')"
python -c "import torch; print(f'PyTorch ç‰ˆæœ¬: {torch.__version__}')"
python -c "import torch; print(f'CUDA å¯ç”¨: {torch.cuda.is_available()}')"
```

---

## ğŸ“¥ æ­¥éª¤1: ä¸‹è½½ Lightning LoRA æƒé‡

### æ–¹æ³•Aï¼šè¿è¡Œä¸‹è½½è„šæœ¬

```bash
python 1_download_lightning_lora.py
```

### æ–¹æ³•Bï¼šæ‰‹åŠ¨ä¸‹è½½å‘½ä»¤

```bash
# ä½¿ç”¨ Hugging Face CLI
huggingface-cli download lightx2v/Qwen-Image-Lightning \
    Qwen-Image-Edit-2509/Qwen-Image-Edit-2509-Lightning-4steps-V1.0-bf16.safetensors \
    --local-dir ./models/lightning_lora
```

### æ–¹æ³•Cï¼šåœ¨çº¿åŠ è½½ï¼ˆæ¨èï¼‰

è„šæœ¬ä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œã€‚

---

## ğŸš€ æ­¥éª¤2: åŠ è½½å¹¶è¿è¡Œæ¨ç†

### å®Œæ•´æµç¨‹ï¼ˆæŒ‰ç…§å®˜æ–¹æŒ‡å¼•ï¼‰

è¿è¡Œå‡†å¤‡å¥½çš„è„šæœ¬ï¼š

```bash
python 2_load_and_inference_lightning.py
```

### ä»£ç è¯´æ˜

è„šæœ¬æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

#### 1. é…ç½®è°ƒåº¦å™¨ï¼ˆå…³é”®é…ç½®ï¼‰

```python
scheduler_config = {
    "base_image_seq_len": 256,
    "base_shift": math.log(3),  # â­ å®˜æ–¹æ¨è
    "use_dynamic_shifting": True,  # â­ é‡è¦ï¼šå¯ç”¨åŠ¨æ€ shifting
    # ... å…¶ä»–é…ç½®
}
scheduler = FlowMatchEulerDiscreteScheduler.from_config(scheduler_config)
```

**å…³é”®å‚æ•°è§£é‡Š**ï¼š
- `base_shift`: `math.log(3)` â‰ˆ 1.099ï¼ˆå®˜æ–¹æ¨èï¼‰
- `use_dynamic_shifting`: `True`ï¼ˆå¿…é¡»å¯ç”¨ï¼Œç”¨äº Lightningï¼‰

#### 2. åŠ è½½åŸºç¡€æ¨¡å‹

```python
pipe = QwenImageEditPipeline.from_pretrained(
    "Qwen/Qwen-Image-Edit",
    scheduler=scheduler,  # â­ ä½¿ç”¨é…ç½®çš„è°ƒåº¦å™¨
    torch_dtype=torch.bfloat16
)
```

#### 3. åŠ è½½ Lightning LoRA

```python
pipe.load_lora_weights(
    "lightx2v/Qwen-Image-Lightning",
    weight_name="Qwen-Image-Edit-2509/Qwen-Image-Edit-2509-Lightning-4steps-V1.0-bf16.safetensors"
)
```

**è‡ªåŠ¨ä¸‹è½½**ï¼šé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½ LoRA æƒé‡ã€‚

#### 4. è¿è¡Œæ¨ç†

```python
output = pipe(
    image=input_image,
    prompt="Change the rabbit's color to purple",
    negative_prompt=" ",
    num_inference_steps=4,  # â­ Lightning: 4æ­¥
    true_cfg_scale=1.0,  # â­ å®˜æ–¹æ¨è 1.0ï¼ˆæ³¨æ„ï¼šä¸æ˜¯ 4.0ï¼‰
    generator=torch.manual_seed(0),
)
```

**å…³é”®å‚æ•°**ï¼š
- `num_inference_steps=4`: Lightning 4æ­¥æ¨ç†
- `true_cfg_scale=1.0`: å®˜æ–¹æ¨èï¼ˆè€ŒéåŸç‰ˆçš„ 4.0ï¼‰

---

## ğŸ”€ æ­¥éª¤3: èåˆ LoRAï¼ˆå¯é€‰ï¼‰

å¦‚æœå¸Œæœ›æ°¸ä¹…ä¿å­˜ Lightning æƒé‡ï¼Œé¿å…æ¯æ¬¡åŠ è½½ LoRAï¼š

```bash
python 3_merge_lora_to_weights.py
```

### èåˆæµç¨‹

```python
# 1. åŠ è½½åŸºç¡€æ¨¡å‹ + LoRA
pipe = QwenImageEditPipeline.from_pretrained("Qwen/Qwen-Image-Edit")
pipe.load_lora_weights("lightx2v/Qwen-Image-Lightning", ...)

# 2. èåˆ LoRA åˆ°æƒé‡
pipe.fuse_lora(lora_scale=1.0)

# 3. ä¿å­˜èåˆåçš„æ¨¡å‹
pipe.save_pretrained("./models/qwen-image-edit-lightning-merged")

# 4. ä¹‹åç›´æ¥åŠ è½½èåˆåçš„æ¨¡å‹ï¼ˆæ— éœ€å†åŠ è½½ LoRAï¼‰
pipe = QwenImageEditPipeline.from_pretrained("./models/qwen-image-edit-lightning-merged")
```

---

## ğŸ“Š ä¸åŸç‰ˆå¯¹æ¯”

| ç‰¹æ€§ | åŸç‰ˆ Qwen-Image-Edit | Lightning ç‰ˆæœ¬ |
|------|---------------------|---------------|
| **æ¨ç†æ­¥æ•°** | 50 æ­¥ | **4 æ­¥** âš¡ |
| **CFG Scale** | 4.0 | **1.0** |
| **è°ƒåº¦å™¨é…ç½®** | é»˜è®¤ | **è‡ªå®šä¹‰** (dynamic shifting) |
| **æ¨¡å‹ç±»å‹** | å®Œæ•´æ¨¡å‹ | **LoRA æƒé‡** |
| **åŠ è½½æ–¹å¼** | `from_pretrained` | `load_lora_weights` |
| **æ¨ç†é€Ÿåº¦** | æ…¢ (~50ç§’) | **å¿« (~4ç§’)** âš¡ |

---

## ğŸ›ï¸ å®Œæ•´å‚æ•°è¯´æ˜

### è°ƒåº¦å™¨å‚æ•°ï¼ˆFlowMatchEulerDiscreteSchedulerï¼‰

```python
{
    "base_image_seq_len": 256,        # åŸºç¡€å›¾åƒåºåˆ—é•¿åº¦
    "base_shift": math.log(3),        # â­ åŸºç¡€åç§»ï¼ˆ1.099ï¼‰
    "max_image_seq_len": 8192,        # æœ€å¤§å›¾åƒåºåˆ—é•¿åº¦
    "max_shift": math.log(3),         # æœ€å¤§åç§»
    "use_dynamic_shifting": True,     # â­ åŠ¨æ€åç§»ï¼ˆå¿…é¡»å¯ç”¨ï¼‰
    "time_shift_type": "exponential", # æ—¶é—´åç§»ç±»å‹
    "num_train_timesteps": 1000,      # è®­ç»ƒæ—¶é—´æ­¥æ•°
}
```

### æ¨ç†å‚æ•°

```python
{
    "image": PIL.Image,               # è¾“å…¥å›¾åƒ
    "prompt": str,                    # ç¼–è¾‘æŒ‡ä»¤
    "negative_prompt": " ",           # è´Ÿé¢æç¤ºè¯ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰
    "num_inference_steps": 4,         # â­ Lightning: 4æ­¥
    "true_cfg_scale": 1.0,            # â­ CFG å¼ºåº¦: 1.0
    "generator": torch.Generator,     # éšæœºæ•°ç”Ÿæˆå™¨
}
```

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. Lightning æ˜¯ LoRAï¼Œä¸æ˜¯å®Œæ•´æ¨¡å‹

- âŒ **é”™è¯¯**: ç›´æ¥ `load_state_dict(lightning_weights)`
- âœ… **æ­£ç¡®**: ä½¿ç”¨ `load_lora_weights()`

### 2. CFG Scale ä½¿ç”¨ 1.0

- Lightning æ¨¡å‹è®­ç»ƒæ—¶ä¼˜åŒ–äº† CFG
- å®˜æ–¹æ¨è `true_cfg_scale=1.0`ï¼ˆè€Œé 4.0ï¼‰

### 3. å¿…é¡»é…ç½®è°ƒåº¦å™¨

- å¿…é¡»ä½¿ç”¨è‡ªå®šä¹‰è°ƒåº¦å™¨é…ç½®
- `base_shift=math.log(3)` å’Œ `use_dynamic_shifting=True` æ˜¯å…³é”®

### 4. æ¨ç†æ­¥æ•°å›ºå®šä¸º 4

- Lightning-4steps è®¾è®¡ä¸º 4 æ­¥æ¨ç†
- ä½¿ç”¨æ›´å¤šæ­¥æ•°ä¸ä¼šæå‡è´¨é‡

---

## ğŸ” éªŒè¯æ­¥éª¤

### æ£€æŸ¥ LoRA æ˜¯å¦åŠ è½½æˆåŠŸ

```python
# æ£€æŸ¥ LoRA é€‚é…å™¨
print("å·²åŠ è½½çš„ LoRA é€‚é…å™¨:", pipe.get_list_adapters())

# æ£€æŸ¥ transformer çš„ LoRA å±‚
for name, module in pipe.transformer.named_modules():
    if "lora" in name.lower():
        print(f"LoRA å±‚: {name}")
```

### æ£€æŸ¥æ¨ç†é€Ÿåº¦

```python
import time

start = time.time()
output = pipe(image, prompt, num_inference_steps=4)
elapsed = time.time() - start

print(f"æ¨ç†æ—¶é—´: {elapsed:.2f} ç§’")
# é¢„æœŸ: ~4-8ç§’ï¼ˆ4æ­¥ï¼‰ï¼Œè€ŒåŸç‰ˆ ~40-50ç§’ï¼ˆ50æ­¥ï¼‰
```

---

## ğŸ“ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

```bash
# 1. å‡†å¤‡ç¯å¢ƒ
pip install git+https://github.com/huggingface/diffusers
pip install torch transformers pillow

# 2. å‡†å¤‡è¾“å…¥å›¾åƒ
# å°†å›¾åƒå‘½åä¸º input.png æ”¾åœ¨å½“å‰ç›®å½•

# 3. è¿è¡Œæ¨ç†ï¼ˆè‡ªåŠ¨ä¸‹è½½ LoRAï¼‰
python 2_load_and_inference_lightning.py

# 4. ï¼ˆå¯é€‰ï¼‰èåˆ LoRA å¹¶ä¿å­˜
python 3_merge_lora_to_weights.py

# 5. æ£€æŸ¥è¾“å‡º
# è¾“å‡ºå›¾åƒ: output_lightning_4steps.png
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: LoRA åŠ è½½å¤±è´¥ï¼Ÿ

**A**: ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½ LoRA æƒé‡æ–‡ä»¶ã€‚

### Q2: æ¨ç†ç»“æœä¸ç†æƒ³ï¼Ÿ

**A**: 
- ç¡®è®¤ `true_cfg_scale=1.0`ï¼ˆä¸æ˜¯ 4.0ï¼‰
- ç¡®è®¤è°ƒåº¦å™¨é…ç½®æ­£ç¡®
- ç¡®è®¤ `num_inference_steps=4`

### Q3: é€Ÿåº¦æ²¡æœ‰æå‡ï¼Ÿ

**A**: 
- ç¡®è®¤ LoRA å·²æˆåŠŸåŠ è½½
- ç¡®è®¤ä½¿ç”¨ 4 æ­¥æ¨ç†ï¼ˆè€Œé 50 æ­¥ï¼‰
- æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† GPU

---

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
F:\Diffusers\
â”œâ”€â”€ 1_download_lightning_lora.py          # ä¸‹è½½è„šæœ¬
â”œâ”€â”€ 2_load_and_inference_lightning.py     # æ¨ç†è„šæœ¬ï¼ˆä¸»è¦ï¼‰
â”œâ”€â”€ 3_merge_lora_to_weights.py            # èåˆè„šæœ¬ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ Lightning_å®Œæ•´æ“ä½œæ­¥éª¤.md             # æœ¬æ–‡æ¡£
â”œâ”€â”€ input.png                             # è¾“å…¥å›¾åƒï¼ˆéœ€å‡†å¤‡ï¼‰
â””â”€â”€ models/
    â”œâ”€â”€ lightning_lora/                   # LoRA æƒé‡ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
    â””â”€â”€ qwen-image-edit-lightning-merged/ # èåˆåæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
```

---

## âœ… æ€»ç»“

**æ ¸å¿ƒæµç¨‹**ï¼ˆ3æ­¥ï¼‰ï¼š

1. **é…ç½®è°ƒåº¦å™¨**ï¼š`base_shift=math.log(3)`, `use_dynamic_shifting=True`
2. **åŠ è½½ LoRA**ï¼š`pipe.load_lora_weights(...)`
3. **4æ­¥æ¨ç†**ï¼š`num_inference_steps=4`, `true_cfg_scale=1.0`

**å…³é”®ä»£ç **ï¼š

```python
# å®Œæ•´æµç¨‹
from diffusers import QwenImageEditPipeline, FlowMatchEulerDiscreteScheduler
import torch, math

scheduler = FlowMatchEulerDiscreteScheduler.from_config({
    "base_shift": math.log(3), "use_dynamic_shifting": True, ...
})

pipe = QwenImageEditPipeline.from_pretrained(
    "Qwen/Qwen-Image-Edit", scheduler=scheduler, torch_dtype=torch.bfloat16
)

pipe.load_lora_weights(
    "lightx2v/Qwen-Image-Lightning",
    weight_name="Qwen-Image-Edit-2509/Qwen-Image-Edit-2509-Lightning-4steps-V1.0-bf16.safetensors"
)

pipe.to("cuda")

output = pipe(image, prompt, num_inference_steps=4, true_cfg_scale=1.0)
```

---

**æŒ‰ç…§æ­¤æ­¥éª¤æ“ä½œå³å¯å®Œå…¨æŒ‰ç…§å®˜æ–¹ Hugging Face æŒ‡å¼•ä½¿ç”¨ Lightning æ¨¡å‹ï¼**

